{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MyNLPToolBox import FilePickling as FP\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in this experiment we're gonna fine-tune the best models we got from the experiment 3, which Logistic Regression with Logarithmic TFIDF Embedder, without removing special characters & stopwords in the corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the pre-embedded dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded obj/x_train_log.pkl\n",
      "loaded obj/x_test_log.pkl\n",
      "loaded obj/y_train.pkl\n",
      "loaded obj/y_test.pkl\n"
     ]
    }
   ],
   "source": [
    "x_train = FP.load_obj('x_train_log')\n",
    "x_test = FP.load_obj('x_test_log')\n",
    "y_train = FP.load_obj('y_train')\n",
    "y_test = FP.load_obj('y_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-Perform Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patri\\Miniconda3\\envs\\tf2\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====\n",
      "LOGISTIC REGRESSION\n",
      "Accuracy:  0.8366373528096587\n",
      "Precision Score:  0.8284383954154728\n",
      "Recall Score:  0.789419795221843\n",
      "F1 Score:  0.8084585809157638\n"
     ]
    }
   ],
   "source": [
    "model_lr = LogisticRegression().fit(x_train,y_train)\n",
    "y_test_pred = model_lr.predict(x_test)\n",
    "print('====\\nLOGISTIC REGRESSION')\n",
    "print('Accuracy: ', accuracy_score(y_test,y_test_pred))\n",
    "print('Precision Score: ', precision_score(y_test,y_test_pred))\n",
    "print('Recall Score: ', recall_score(y_test,y_test_pred))\n",
    "print('F1 Score: ', f1_score(y_test,y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright! The accuracy and recall score are quite high. However, now we're gonna finetune this model to make it even better!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "As sklearn use the threshold of 0.5, now we're gonna try different threshold to see what if the perfomance is gained on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THRESHOLD  0.1\n",
      "Accuracy:  0.820688627217171\n",
      "Precision Score:  0.7446868801360159\n",
      "Recall Score:  0.8969283276450511\n",
      "F1 Score:  0.8137482582443103\n",
      "---\n",
      "THRESHOLD  0.2\n",
      "Accuracy:  0.8303771053808318\n",
      "Precision Score:  0.776885043263288\n",
      "Recall Score:  0.8580204778156997\n",
      "F1 Score:  0.8154395069737268\n",
      "---\n",
      "THRESHOLD  0.30000000000000004\n",
      "Accuracy:  0.8339543896258756\n",
      "Precision Score:  0.7959582790091264\n",
      "Recall Score:  0.8334470989761092\n",
      "F1 Score:  0.8142714238079359\n",
      "---\n",
      "THRESHOLD  0.4\n",
      "Accuracy:  0.8373826203607095\n",
      "Precision Score:  0.8137154554759468\n",
      "Recall Score:  0.8139931740614335\n",
      "F1 Score:  0.8138542910766081\n",
      "---\n",
      "THRESHOLD  0.5\n",
      "Accuracy:  0.8366373528096587\n",
      "Precision Score:  0.8284383954154728\n",
      "Recall Score:  0.789419795221843\n",
      "F1 Score:  0.8084585809157638\n",
      "---\n",
      "THRESHOLD  0.6\n",
      "Accuracy:  0.8357430317483977\n",
      "Precision Score:  0.8441265060240963\n",
      "Recall Score:  0.7651877133105802\n",
      "F1 Score:  0.8027210884353742\n",
      "---\n",
      "THRESHOLD  0.7000000000000001\n",
      "Accuracy:  0.8345506036667164\n",
      "Precision Score:  0.8602533650039589\n",
      "Recall Score:  0.7416382252559727\n",
      "F1 Score:  0.7965542521994136\n",
      "---\n",
      "THRESHOLD  0.8\n",
      "Accuracy:  0.82888657027873\n",
      "Precision Score:  0.8791489361702127\n",
      "Recall Score:  0.7051194539249147\n",
      "F1 Score:  0.7825757575757575\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "thresholds = np.arange(0.1,0.9,0.1) # All threshold from 0.1 -> 0.9 with step of 0.1\n",
    "for thresh in thresholds:\n",
    "    print('THRESHOLD ',thresh)\n",
    "    y_test_pred = [1  if prob[1] > thresh else 0 for prob in model_lr.predict_proba(x_test)]\n",
    "    print('Accuracy: ', accuracy_score(y_test,y_test_pred))\n",
    "    print('Precision Score: ', precision_score(y_test,y_test_pred))\n",
    "    print('Recall Score: ', recall_score(y_test,y_test_pred))\n",
    "    print('F1 Score: ', f1_score(y_test,y_test_pred))\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the hyperparam is somewhere between 0.3 -> 0.5, we're going to investigate this range more specifically :D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THRESHOLD  0.3\n",
      "Accuracy:  0.8339543896258756\n",
      "Precision Score:  0.7959582790091264\n",
      "Recall Score:  0.8334470989761092\n",
      "F1 Score:  0.8142714238079359\n",
      "---\n",
      "THRESHOLD  0.31\n",
      "Accuracy:  0.8344015501565062\n",
      "Precision Score:  0.7977086743044189\n",
      "Recall Score:  0.831740614334471\n",
      "F1 Score:  0.8143692564745196\n",
      "---\n",
      "THRESHOLD  0.32\n",
      "Accuracy:  0.835146817707557\n",
      "Precision Score:  0.8003952569169961\n",
      "Recall Score:  0.8293515358361775\n",
      "F1 Score:  0.8146161582299699\n",
      "---\n",
      "THRESHOLD  0.33\n",
      "Accuracy:  0.8358920852586078\n",
      "Precision Score:  0.8021143045920053\n",
      "Recall Score:  0.8286689419795222\n",
      "F1 Score:  0.8151754238710761\n",
      "---\n",
      "THRESHOLD  0.34\n",
      "Accuracy:  0.8358920852586078\n",
      "Precision Score:  0.8033167495854063\n",
      "Recall Score:  0.8266211604095564\n",
      "F1 Score:  0.814802354920101\n",
      "---\n",
      "THRESHOLD  0.35000000000000003\n",
      "Accuracy:  0.8357430317483977\n",
      "Precision Score:  0.8040585495675316\n",
      "Recall Score:  0.8249146757679181\n",
      "F1 Score:  0.8143530997304583\n",
      "---\n",
      "THRESHOLD  0.36000000000000004\n",
      "Accuracy:  0.836041138768818\n",
      "Precision Score:  0.8056112224448898\n",
      "Recall Score:  0.8232081911262799\n",
      "F1 Score:  0.8143146522619851\n",
      "---\n",
      "THRESHOLD  0.37000000000000005\n",
      "Accuracy:  0.8366373528096587\n",
      "Precision Score:  0.8081317204301075\n",
      "Recall Score:  0.8208191126279863\n",
      "F1 Score:  0.8144260074500509\n",
      "---\n",
      "THRESHOLD  0.38000000000000006\n",
      "Accuracy:  0.8373826203607095\n",
      "Precision Score:  0.8105369807497467\n",
      "Recall Score:  0.8191126279863481\n",
      "F1 Score:  0.8148022407061619\n",
      "---\n",
      "THRESHOLD  0.39000000000000007\n",
      "Accuracy:  0.8370845133402892\n",
      "Precision Score:  0.8116728876823889\n",
      "Recall Score:  0.816382252559727\n",
      "F1 Score:  0.8140207588905904\n",
      "---\n",
      "THRESHOLD  0.4000000000000001\n",
      "Accuracy:  0.8373826203607095\n",
      "Precision Score:  0.8137154554759468\n",
      "Recall Score:  0.8139931740614335\n",
      "F1 Score:  0.8138542910766081\n",
      "---\n",
      "THRESHOLD  0.4100000000000001\n",
      "Accuracy:  0.8363392457892384\n",
      "Precision Score:  0.8145604395604396\n",
      "Recall Score:  0.8095563139931741\n",
      "F1 Score:  0.8120506675795961\n",
      "---\n",
      "THRESHOLD  0.4200000000000001\n",
      "Accuracy:  0.8367864063198688\n",
      "Precision Score:  0.8162702516373664\n",
      "Recall Score:  0.8081911262798634\n",
      "F1 Score:  0.8122105985251243\n",
      "---\n",
      "THRESHOLD  0.4300000000000001\n",
      "Accuracy:  0.8373826203607095\n",
      "Precision Score:  0.8187175043327556\n",
      "Recall Score:  0.8061433447098976\n",
      "F1 Score:  0.8123817712811694\n",
      "---\n",
      "THRESHOLD  0.4400000000000001\n",
      "Accuracy:  0.8375316738709196\n",
      "Precision Score:  0.8203342618384402\n",
      "Recall Score:  0.8040955631399317\n",
      "F1 Score:  0.8121337469837986\n",
      "---\n",
      "THRESHOLD  0.4500000000000001\n",
      "Accuracy:  0.8375316738709196\n",
      "Precision Score:  0.8221288515406162\n",
      "Recall Score:  0.8013651877133106\n",
      "F1 Score:  0.811614241272036\n",
      "---\n",
      "THRESHOLD  0.46000000000000013\n",
      "Accuracy:  0.8373826203607095\n",
      "Precision Score:  0.8229715489989463\n",
      "Recall Score:  0.7996587030716723\n",
      "F1 Score:  0.8111476544919508\n",
      "---\n",
      "THRESHOLD  0.47000000000000014\n",
      "Accuracy:  0.8367864063198688\n",
      "Precision Score:  0.8243195475433015\n",
      "Recall Score:  0.7959044368600683\n",
      "F1 Score:  0.8098628234068416\n",
      "---\n",
      "THRESHOLD  0.48000000000000015\n",
      "Accuracy:  0.8364882992994485\n",
      "Precision Score:  0.8258087451119801\n",
      "Recall Score:  0.7928327645051194\n",
      "F1 Score:  0.8089848511231064\n",
      "---\n",
      "THRESHOLD  0.49000000000000016\n",
      "Accuracy:  0.8363392457892384\n",
      "Precision Score:  0.8269093504639543\n",
      "Recall Score:  0.7907849829351535\n",
      "F1 Score:  0.80844382414515\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "thresholds = np.arange(0.3,0.5,0.01) # All threshold from 0.3 -> 0.5 with step of 0.01\n",
    "for thresh in thresholds:\n",
    "    print('THRESHOLD ',thresh)\n",
    "    y_test_pred = [1  if prob[1] > thresh else 0 for prob in model_lr.predict_proba(x_test)]\n",
    "    print('Accuracy: ', accuracy_score(y_test,y_test_pred))\n",
    "    print('Precision Score: ', precision_score(y_test,y_test_pred))\n",
    "    print('Recall Score: ', recall_score(y_test,y_test_pred))\n",
    "    print('F1 Score: ', f1_score(y_test,y_test_pred))\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So at the end our best threshold is 0.44 which gave us accuracy **0.8375** and F1 score of **0.8121** :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
