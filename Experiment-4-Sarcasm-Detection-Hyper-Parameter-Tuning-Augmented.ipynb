{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MyNLPToolBox import FilePickling as FP\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in this experiment we're gonna fine-tune the best model we got from the experiment 3, which Logistic Regression with Augmented TFIDF Embedder, without removing special characters & stopwords in the corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the pre-embedded dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded obj/x_train_best.pkl\n",
      "loaded obj/x_test_best.pkl\n",
      "loaded obj/y_train.pkl\n",
      "loaded obj/y_test.pkl\n"
     ]
    }
   ],
   "source": [
    "x_train = FP.load_obj('x_train_aug')\n",
    "x_test = FP.load_obj('x_test_aug')\n",
    "y_train = FP.load_obj('y_train')\n",
    "y_test = FP.load_obj('y_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-Perform Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====\n",
      "LOGISTIC REGRESSION\n",
      "Accuracy:  0.8373826203607095\n",
      "Precision Score:  0.829688060236644\n",
      "Recall Score:  0.7897610921501707\n",
      "F1 Score:  0.8092323832837909\n"
     ]
    }
   ],
   "source": [
    "model_lr = LogisticRegression().fit(x_train,y_train)\n",
    "y_test_pred = model_lr.predict(x_test)\n",
    "print('====\\nLOGISTIC REGRESSION')\n",
    "print('Accuracy: ', accuracy_score(y_test,y_test_pred))\n",
    "print('Precision Score: ', precision_score(y_test,y_test_pred))\n",
    "print('Recall Score: ', recall_score(y_test,y_test_pred))\n",
    "print('F1 Score: ', f1_score(y_test,y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright! The accuracy and recall score are quite high. However, now we're gonna finetune this model to make it even better!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "As sklearn use the threshold of 0.5, now we're gonna try different threshold to see what if the perfomance is gained on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THRESHOLD  0.1\n",
      "Accuracy:  0.8193471456252794\n",
      "Precision Score:  0.7440340909090909\n",
      "Recall Score:  0.8938566552901024\n",
      "F1 Score:  0.812093023255814\n",
      "---\n",
      "THRESHOLD  0.2\n",
      "Accuracy:  0.8303771053808318\n",
      "Precision Score:  0.7760320394331485\n",
      "Recall Score:  0.8597269624573379\n",
      "F1 Score:  0.8157383419689119\n",
      "---\n",
      "THRESHOLD  0.30000000000000004\n",
      "Accuracy:  0.8339543896258756\n",
      "Precision Score:  0.7948051948051948\n",
      "Recall Score:  0.8354948805460751\n",
      "F1 Score:  0.8146422628951748\n",
      "---\n",
      "THRESHOLD  0.4\n",
      "Accuracy:  0.8367864063198688\n",
      "Precision Score:  0.8128196385952949\n",
      "Recall Score:  0.8136518771331058\n",
      "F1 Score:  0.8132355449428619\n",
      "---\n",
      "THRESHOLD  0.5\n",
      "Accuracy:  0.8373826203607095\n",
      "Precision Score:  0.829688060236644\n",
      "Recall Score:  0.7897610921501707\n",
      "F1 Score:  0.8092323832837909\n",
      "---\n",
      "THRESHOLD  0.6\n",
      "Accuracy:  0.834252496646296\n",
      "Precision Score:  0.8414725770097671\n",
      "Recall Score:  0.764505119453925\n",
      "F1 Score:  0.8011444921316166\n",
      "---\n",
      "THRESHOLD  0.7000000000000001\n",
      "Accuracy:  0.8339543896258756\n",
      "Precision Score:  0.8591772151898734\n",
      "Recall Score:  0.741296928327645\n",
      "F1 Score:  0.7958959325760353\n",
      "---\n",
      "THRESHOLD  0.8\n",
      "Accuracy:  0.8281413027276793\n",
      "Precision Score:  0.8750527648796961\n",
      "Recall Score:  0.7075085324232082\n",
      "F1 Score:  0.7824117758067561\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "thresholds = np.arange(0.1,0.9,0.1) # All threshold from 0.1 -> 0.9 with step of 0.1\n",
    "for thresh in thresholds:\n",
    "    print('THRESHOLD ',thresh)\n",
    "    y_test_pred = [1  if prob[1] > thresh else 0 for prob in model_lr.predict_proba(x_test)]\n",
    "    print('Accuracy: ', accuracy_score(y_test,y_test_pred))\n",
    "    print('Precision Score: ', precision_score(y_test,y_test_pred))\n",
    "    print('Recall Score: ', recall_score(y_test,y_test_pred))\n",
    "    print('F1 Score: ', f1_score(y_test,y_test_pred))\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the hyperparam is somewhere between 0.4 -> 0.5, we're going to investigate this range more specifically :D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THRESHOLD  0.4\n",
      "Accuracy:  0.8367864063198688\n",
      "Precision Score:  0.8128196385952949\n",
      "Recall Score:  0.8136518771331058\n",
      "F1 Score:  0.8132355449428619\n",
      "---\n",
      "THRESHOLD  0.41000000000000003\n",
      "Accuracy:  0.8367864063198688\n",
      "Precision Score:  0.8147512864493996\n",
      "Recall Score:  0.810580204778157\n",
      "F1 Score:  0.8126603934987169\n",
      "---\n",
      "THRESHOLD  0.42000000000000004\n",
      "Accuracy:  0.836935459830079\n",
      "Precision Score:  0.8161157024793388\n",
      "Recall Score:  0.8088737201365188\n",
      "F1 Score:  0.8124785738772712\n",
      "---\n",
      "THRESHOLD  0.43000000000000005\n",
      "Accuracy:  0.8367864063198688\n",
      "Precision Score:  0.8173642338291248\n",
      "Recall Score:  0.8064846416382253\n",
      "F1 Score:  0.8118879917539942\n",
      "---\n",
      "THRESHOLD  0.44000000000000006\n",
      "Accuracy:  0.8372335668504993\n",
      "Precision Score:  0.8193189715079917\n",
      "Recall Score:  0.8047781569965871\n",
      "F1 Score:  0.8119834710743801\n",
      "---\n",
      "THRESHOLD  0.45000000000000007\n",
      "Accuracy:  0.8373826203607095\n",
      "Precision Score:  0.8209424083769633\n",
      "Recall Score:  0.8027303754266212\n",
      "F1 Score:  0.8117342536669543\n",
      "---\n",
      "THRESHOLD  0.4600000000000001\n",
      "Accuracy:  0.8376807273811299\n",
      "Precision Score:  0.8240056318197818\n",
      "Recall Score:  0.798976109215017\n",
      "F1 Score:  0.8112978686536129\n",
      "---\n",
      "THRESHOLD  0.4700000000000001\n",
      "Accuracy:  0.8379788344015502\n",
      "Precision Score:  0.8252735615954818\n",
      "Recall Score:  0.7979522184300342\n",
      "F1 Score:  0.8113829602637516\n",
      "---\n",
      "THRESHOLD  0.4800000000000001\n",
      "Accuracy:  0.8376807273811299\n",
      "Precision Score:  0.8267660631877884\n",
      "Recall Score:  0.7948805460750853\n",
      "F1 Score:  0.8105098312162867\n",
      "---\n",
      "THRESHOLD  0.4900000000000001\n",
      "Accuracy:  0.8372335668504993\n",
      "Precision Score:  0.8282142857142857\n",
      "Recall Score:  0.7914675767918089\n",
      "F1 Score:  0.8094240837696336\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "thresholds = np.arange(0.4,0.5,0.01) # All threshold from 0.1 -> 0.9 with step of 0.1\n",
    "for thresh in thresholds:\n",
    "    print('THRESHOLD ',thresh)\n",
    "    y_test_pred = [1  if prob[1] > thresh else 0 for prob in model_lr.predict_proba(x_test)]\n",
    "    print('Accuracy: ', accuracy_score(y_test,y_test_pred))\n",
    "    print('Precision Score: ', precision_score(y_test,y_test_pred))\n",
    "    print('Recall Score: ', recall_score(y_test,y_test_pred))\n",
    "    print('F1 Score: ', f1_score(y_test,y_test_pred))\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the hyperparam is somewhere between 0.46 -> 0.48, we're going to investigate this range more specifically :D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THRESHOLD  0.46\n",
      "Accuracy:  0.8376807273811299\n",
      "Precision Score:  0.8240056318197818\n",
      "Recall Score:  0.798976109215017\n",
      "F1 Score:  0.8112978686536129\n",
      "---\n",
      "THRESHOLD  0.461\n",
      "Accuracy:  0.8379788344015502\n",
      "Precision Score:  0.8245861218738992\n",
      "Recall Score:  0.798976109215017\n",
      "F1 Score:  0.81157912983186\n",
      "---\n",
      "THRESHOLD  0.462\n",
      "Accuracy:  0.8379788344015502\n",
      "Precision Score:  0.8245861218738992\n",
      "Recall Score:  0.798976109215017\n",
      "F1 Score:  0.81157912983186\n",
      "---\n",
      "THRESHOLD  0.463\n",
      "Accuracy:  0.83782978089134\n",
      "Precision Score:  0.8245243128964059\n",
      "Recall Score:  0.7986348122866894\n",
      "F1 Score:  0.8113730929264911\n",
      "---\n",
      "THRESHOLD  0.464\n",
      "Accuracy:  0.83782978089134\n",
      "Precision Score:  0.8245243128964059\n",
      "Recall Score:  0.7986348122866894\n",
      "F1 Score:  0.8113730929264911\n",
      "---\n",
      "THRESHOLD  0.465\n",
      "Accuracy:  0.8379788344015502\n",
      "Precision Score:  0.824814945364822\n",
      "Recall Score:  0.7986348122866894\n",
      "F1 Score:  0.8115137853303278\n",
      "---\n",
      "THRESHOLD  0.466\n",
      "Accuracy:  0.83782978089134\n",
      "Precision Score:  0.82475317348378\n",
      "Recall Score:  0.7982935153583618\n",
      "F1 Score:  0.8113076656260839\n",
      "---\n",
      "THRESHOLD  0.467\n",
      "Accuracy:  0.83782978089134\n",
      "Precision Score:  0.8249823570924488\n",
      "Recall Score:  0.7979522184300342\n",
      "F1 Score:  0.8112421929215823\n",
      "---\n",
      "THRESHOLD  0.468\n",
      "Accuracy:  0.83782978089134\n",
      "Precision Score:  0.8249823570924488\n",
      "Recall Score:  0.7979522184300342\n",
      "F1 Score:  0.8112421929215823\n",
      "---\n",
      "THRESHOLD  0.46900000000000003\n",
      "Accuracy:  0.8379788344015502\n",
      "Precision Score:  0.8252735615954818\n",
      "Recall Score:  0.7979522184300342\n",
      "F1 Score:  0.8113829602637516\n",
      "---\n",
      "THRESHOLD  0.47000000000000003\n",
      "Accuracy:  0.8379788344015502\n",
      "Precision Score:  0.8252735615954818\n",
      "Recall Score:  0.7979522184300342\n",
      "F1 Score:  0.8113829602637516\n",
      "---\n",
      "THRESHOLD  0.47100000000000003\n",
      "Accuracy:  0.8382769414219705\n",
      "Precision Score:  0.8258565877781703\n",
      "Recall Score:  0.7979522184300342\n",
      "F1 Score:  0.8116646415552856\n",
      "---\n",
      "THRESHOLD  0.47200000000000003\n",
      "Accuracy:  0.8381278879117603\n",
      "Precision Score:  0.8257950530035336\n",
      "Recall Score:  0.7976109215017065\n",
      "F1 Score:  0.8114583333333335\n",
      "---\n",
      "THRESHOLD  0.47300000000000003\n",
      "Accuracy:  0.8381278879117603\n",
      "Precision Score:  0.8257950530035336\n",
      "Recall Score:  0.7976109215017065\n",
      "F1 Score:  0.8114583333333335\n",
      "---\n",
      "THRESHOLD  0.47400000000000003\n",
      "Accuracy:  0.83782978089134\n",
      "Precision Score:  0.8256718528995757\n",
      "Recall Score:  0.7969283276450512\n",
      "F1 Score:  0.8110455019103856\n",
      "---\n",
      "THRESHOLD  0.47500000000000003\n",
      "Accuracy:  0.8376807273811299\n",
      "Precision Score:  0.8256101874778917\n",
      "Recall Score:  0.7965870307167235\n",
      "F1 Score:  0.8108389786347057\n",
      "---\n",
      "THRESHOLD  0.47600000000000003\n",
      "Accuracy:  0.8375316738709196\n",
      "Precision Score:  0.8257790368271954\n",
      "Recall Score:  0.7959044368600683\n",
      "F1 Score:  0.8105665623913799\n",
      "---\n",
      "THRESHOLD  0.47700000000000004\n",
      "Accuracy:  0.8376807273811299\n",
      "Precision Score:  0.8260715550832448\n",
      "Recall Score:  0.7959044368600683\n",
      "F1 Score:  0.8107074569789674\n",
      "---\n",
      "THRESHOLD  0.47800000000000004\n",
      "Accuracy:  0.83782978089134\n",
      "Precision Score:  0.8263642806520198\n",
      "Recall Score:  0.7959044368600683\n",
      "F1 Score:  0.8108484005563283\n",
      "---\n",
      "THRESHOLD  0.47900000000000004\n",
      "Accuracy:  0.83782978089134\n",
      "Precision Score:  0.8268275372604684\n",
      "Recall Score:  0.7952218430034129\n",
      "F1 Score:  0.8107167710508002\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "thresholds = np.arange(0.46,0.48,0.001) # All threshold from 0.1 -> 0.9 with step of 0.1\n",
    "for thresh in thresholds:\n",
    "    print('THRESHOLD ',thresh)\n",
    "    y_test_pred = [1  if prob[1] > thresh else 0 for prob in model_lr.predict_proba(x_test)]\n",
    "    print('Accuracy: ', accuracy_score(y_test,y_test_pred))\n",
    "    print('Precision Score: ', precision_score(y_test,y_test_pred))\n",
    "    print('Recall Score: ', recall_score(y_test,y_test_pred))\n",
    "    print('F1 Score: ', f1_score(y_test,y_test_pred))\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the hyperparam is somewhere between 0.47 -> 0.472, we're going to investigate this range more specifically :D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THRESHOLD  0.47\n",
      "Accuracy:  0.8379788344015502\n",
      "Precision Score:  0.8252735615954818\n",
      "Recall Score:  0.7979522184300342\n",
      "F1 Score:  0.8113829602637516\n",
      "---\n",
      "THRESHOLD  0.47009999999999996\n",
      "Accuracy:  0.8379788344015502\n",
      "Precision Score:  0.8252735615954818\n",
      "Recall Score:  0.7979522184300342\n",
      "F1 Score:  0.8113829602637516\n",
      "---\n",
      "THRESHOLD  0.47019999999999995\n",
      "Accuracy:  0.8381278879117603\n",
      "Precision Score:  0.8255649717514124\n",
      "Recall Score:  0.7979522184300342\n",
      "F1 Score:  0.8115237764665046\n",
      "---\n",
      "THRESHOLD  0.47029999999999994\n",
      "Accuracy:  0.8382769414219705\n",
      "Precision Score:  0.8258565877781703\n",
      "Recall Score:  0.7979522184300342\n",
      "F1 Score:  0.8116646415552856\n",
      "---\n",
      "THRESHOLD  0.47039999999999993\n",
      "Accuracy:  0.8382769414219705\n",
      "Precision Score:  0.8258565877781703\n",
      "Recall Score:  0.7979522184300342\n",
      "F1 Score:  0.8116646415552856\n",
      "---\n",
      "THRESHOLD  0.4704999999999999\n",
      "Accuracy:  0.8382769414219705\n",
      "Precision Score:  0.8258565877781703\n",
      "Recall Score:  0.7979522184300342\n",
      "F1 Score:  0.8116646415552856\n",
      "---\n",
      "THRESHOLD  0.4705999999999999\n",
      "Accuracy:  0.8382769414219705\n",
      "Precision Score:  0.8258565877781703\n",
      "Recall Score:  0.7979522184300342\n",
      "F1 Score:  0.8116646415552856\n",
      "---\n",
      "THRESHOLD  0.4706999999999999\n",
      "Accuracy:  0.8382769414219705\n",
      "Precision Score:  0.8258565877781703\n",
      "Recall Score:  0.7979522184300342\n",
      "F1 Score:  0.8116646415552856\n",
      "---\n",
      "THRESHOLD  0.4707999999999999\n",
      "Accuracy:  0.8382769414219705\n",
      "Precision Score:  0.8258565877781703\n",
      "Recall Score:  0.7979522184300342\n",
      "F1 Score:  0.8116646415552856\n",
      "---\n",
      "THRESHOLD  0.4708999999999999\n",
      "Accuracy:  0.8382769414219705\n",
      "Precision Score:  0.8258565877781703\n",
      "Recall Score:  0.7979522184300342\n",
      "F1 Score:  0.8116646415552856\n",
      "---\n",
      "THRESHOLD  0.47099999999999986\n",
      "Accuracy:  0.8382769414219705\n",
      "Precision Score:  0.8258565877781703\n",
      "Recall Score:  0.7979522184300342\n",
      "F1 Score:  0.8116646415552856\n",
      "---\n",
      "THRESHOLD  0.47109999999999985\n",
      "Accuracy:  0.8382769414219705\n",
      "Precision Score:  0.8258565877781703\n",
      "Recall Score:  0.7979522184300342\n",
      "F1 Score:  0.8116646415552856\n",
      "---\n",
      "THRESHOLD  0.47119999999999984\n",
      "Accuracy:  0.8382769414219705\n",
      "Precision Score:  0.8258565877781703\n",
      "Recall Score:  0.7979522184300342\n",
      "F1 Score:  0.8116646415552856\n",
      "---\n",
      "THRESHOLD  0.47129999999999983\n",
      "Accuracy:  0.8382769414219705\n",
      "Precision Score:  0.8258565877781703\n",
      "Recall Score:  0.7979522184300342\n",
      "F1 Score:  0.8116646415552856\n",
      "---\n",
      "THRESHOLD  0.4713999999999998\n",
      "Accuracy:  0.8382769414219705\n",
      "Precision Score:  0.8258565877781703\n",
      "Recall Score:  0.7979522184300342\n",
      "F1 Score:  0.8116646415552856\n",
      "---\n",
      "THRESHOLD  0.4714999999999998\n",
      "Accuracy:  0.8381278879117603\n",
      "Precision Score:  0.8257950530035336\n",
      "Recall Score:  0.7976109215017065\n",
      "F1 Score:  0.8114583333333335\n",
      "---\n",
      "THRESHOLD  0.4715999999999998\n",
      "Accuracy:  0.8381278879117603\n",
      "Precision Score:  0.8257950530035336\n",
      "Recall Score:  0.7976109215017065\n",
      "F1 Score:  0.8114583333333335\n",
      "---\n",
      "THRESHOLD  0.4716999999999998\n",
      "Accuracy:  0.8381278879117603\n",
      "Precision Score:  0.8257950530035336\n",
      "Recall Score:  0.7976109215017065\n",
      "F1 Score:  0.8114583333333335\n",
      "---\n",
      "THRESHOLD  0.4717999999999998\n",
      "Accuracy:  0.8381278879117603\n",
      "Precision Score:  0.8257950530035336\n",
      "Recall Score:  0.7976109215017065\n",
      "F1 Score:  0.8114583333333335\n",
      "---\n",
      "THRESHOLD  0.47189999999999976\n",
      "Accuracy:  0.8381278879117603\n",
      "Precision Score:  0.8257950530035336\n",
      "Recall Score:  0.7976109215017065\n",
      "F1 Score:  0.8114583333333335\n",
      "---\n",
      "THRESHOLD  0.47199999999999975\n",
      "Accuracy:  0.8381278879117603\n",
      "Precision Score:  0.8257950530035336\n",
      "Recall Score:  0.7976109215017065\n",
      "F1 Score:  0.8114583333333335\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "thresholds = np.arange(0.47,0.472,0.0001) # All threshold from 0.1 -> 0.9 with step of 0.1\n",
    "for thresh in thresholds:\n",
    "    print('THRESHOLD ',thresh)\n",
    "    y_test_pred = [1  if prob[1] > thresh else 0 for prob in model_lr.predict_proba(x_test)]\n",
    "    print('Accuracy: ', accuracy_score(y_test,y_test_pred))\n",
    "    print('Precision Score: ', precision_score(y_test,y_test_pred))\n",
    "    print('Recall Score: ', recall_score(y_test,y_test_pred))\n",
    "    print('F1 Score: ', f1_score(y_test,y_test_pred))\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So at the end our best threshold is 0.47 which gave us accuracy **83.83%** and F1 score of **0.813** :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
